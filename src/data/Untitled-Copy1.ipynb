{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a442afce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1144f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/shared/0/projects/research-jam-summer-2024/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e93a484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['llama3.1_70B_100_sample_with_metrics.jsonl',\n",
       " 'wildchat_subset_en_2k_prompting_Mistral-7B-Instruct-v0.3-lexical.jsonl',\n",
       " 'llama_3.1-70B_100_sample.jsonl',\n",
       " 'wildchat_subset_en_2k_prompting_Mistral-7B-Instruct-v0.3.jsonl',\n",
       " 'wildchat_subset_en_2k_prompting_Meta-Llama-3.1-8B-Instruct.jsonl',\n",
       " 'mixtral_100_sample_with_metrics.jsonl',\n",
       " 'mixtral_100_sample.jsonl',\n",
       " 'wildchat_subset_en_2k_prompting_Meta-Llama-3.1-70B-Instruct.jsonl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data/english_only/prompting_results_clean/with_metrics/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2d5e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_dir = 'data/english_only/prompting_results_clean/with_metrics/'\n",
    "fname = os.listdir(mod_dir)[0] #there are 4 files here\n",
    "\n",
    "data = pd.read_json(mod_dir + fname, orient='records', lines=True)\n",
    "data = data[data.llm_turn_3 != 'INVALID_DO_NOT_USE]']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c37f770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/home/akananth/Misc/human-llm-similarity/src')\n",
    "\n",
    "#from analysis.pos_tags_JSD import pos_tag_metric\n",
    "#from analysis.liwc_dist_extractor import LiwcDistExtractor\n",
    "#from analysis.embedding_similarity import EmbeddingSimilarity\n",
    "#from analysis.capitalization_punctuation_similarity import capitalization, punctuation\n",
    "from analysis.syntactic_metrics import BasicSyntacticStatistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45a60809-353f-48f9-b2eb-3e44cc91c687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_turn_1</th>\n",
       "      <th>ai_turn_2</th>\n",
       "      <th>human_turn_3</th>\n",
       "      <th>hashed_ip</th>\n",
       "      <th>model</th>\n",
       "      <th>country</th>\n",
       "      <th>language</th>\n",
       "      <th>conversation_hash</th>\n",
       "      <th>turn</th>\n",
       "      <th>toxic</th>\n",
       "      <th>...</th>\n",
       "      <th>llm_pos</th>\n",
       "      <th>llm_readability</th>\n",
       "      <th>llm_sentiment</th>\n",
       "      <th>llm_topic</th>\n",
       "      <th>metric_formality</th>\n",
       "      <th>metric_pos</th>\n",
       "      <th>metric_readability</th>\n",
       "      <th>metric_sbert</th>\n",
       "      <th>metric_sentiment</th>\n",
       "      <th>metric_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are part of a team of bots that creates im...</td>\n",
       "      <td>[In a serene forest clearing bathed in soft da...</td>\n",
       "      <td>Avoid the word intimate, and make it wetter</td>\n",
       "      <td>568ecf3349b46c238268f63bcdbb2e12cd88feea3052b9...</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>231dc924f9bf607871bf3e5699930833</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'ADJ': 0.09259259260000001, 'ADP': 0.07407407...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.813772</td>\n",
       "      <td>[0.0828052163, 0.2082787901, 0.043125897600000...</td>\n",
       "      <td>0.005368</td>\n",
       "      <td>0.713367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.220994</td>\n",
       "      <td>0.103876</td>\n",
       "      <td>0.819343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it appears that the Chatgpt 3.5 token limit of...</td>\n",
       "      <td>I apologize for any inconvenience caused by th...</td>\n",
       "      <td>is there anything i can do about it</td>\n",
       "      <td>d3c81b62172c8e48ca874e118ee957e3db84d1f9b4d5b1...</td>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>edf58f8e33a00f9c374d448aad703650</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'ADJ': 0.0410958904, 'ADP': 0.1095890411, 'AD...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016861</td>\n",
       "      <td>[0.13737380500000002, 0.10264397410000001, 0.0...</td>\n",
       "      <td>0.172894</td>\n",
       "      <td>0.650372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.115637</td>\n",
       "      <td>-0.446227</td>\n",
       "      <td>0.847331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weight reduction can be achieved, among others...</td>\n",
       "      <td>One way to achieve weight reduction is by inco...</td>\n",
       "      <td>An important direction in the construction of ...</td>\n",
       "      <td>6e9b81c31754d99e4f9df95bd6317c844f444f4eedd216...</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>Poland</td>\n",
       "      <td>English</td>\n",
       "      <td>544d60f14b495ca7e7ae9dbe2ed63220</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'ADJ': 0.1538461538, 'ADP': 0.0769230769, 'AD...</td>\n",
       "      <td>0.525182</td>\n",
       "      <td>0.500640</td>\n",
       "      <td>[0.1245699078, 0.1347142458, 0.0831267238, 0.0...</td>\n",
       "      <td>-0.518432</td>\n",
       "      <td>0.682936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225023</td>\n",
       "      <td>-0.185854</td>\n",
       "      <td>0.871312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In addition, among the co-incorporated NML, as...</td>\n",
       "      <td>Furthermore, when a higher amount of copper (C...</td>\n",
       "      <td>In addition, among the co-incorporated NML, as...</td>\n",
       "      <td>5ed67e4bf7e0054269cd7281f76a05f7fa75bf36856ea7...</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>Macao</td>\n",
       "      <td>English</td>\n",
       "      <td>1f63b7d1807287f1d1ecfb8710075789</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'ADJ': 0.0952380952, 'ADP': 0.0555555556, 'AD...</td>\n",
       "      <td>0.219182</td>\n",
       "      <td>0.652610</td>\n",
       "      <td>[0.0807779357, 0.1165298745, 0.049247577800000...</td>\n",
       "      <td>0.099297</td>\n",
       "      <td>0.720727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.608043</td>\n",
       "      <td>0.031958</td>\n",
       "      <td>0.679667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>اريد كود في اندرويد ستوديو كوتلن حذف خلفية الص...</td>\n",
       "      <td>ستحتاج إلى استخدام مكتبة TensorFlow Lite لإزال...</td>\n",
       "      <td>ارجوا كتابة كود xml هذا الكود class MainActivi...</td>\n",
       "      <td>c29121a61bae1319376607d7a8475b8a7339ee288fa66c...</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>English</td>\n",
       "      <td>245490794224427cf7c4be8fdba35f8c</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'ADJ': 0.0862068966, 'ADP': 0, 'ADV': 0, 'CON...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.587915</td>\n",
       "      <td>[0.15139885250000001, 0.0965454951, 0.07890398...</td>\n",
       "      <td>-0.005296</td>\n",
       "      <td>0.714621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.081709</td>\n",
       "      <td>-0.105480</td>\n",
       "      <td>0.661341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         human_turn_1  \\\n",
       "0   You are part of a team of bots that creates im...   \n",
       "1   it appears that the Chatgpt 3.5 token limit of...   \n",
       "2   Weight reduction can be achieved, among others...   \n",
       "3   In addition, among the co-incorporated NML, as...   \n",
       "4   اريد كود في اندرويد ستوديو كوتلن حذف خلفية الص...   \n",
       "..                                                ...   \n",
       "95                                               None   \n",
       "96                                               None   \n",
       "97                                               None   \n",
       "98                                               None   \n",
       "99                                               None   \n",
       "\n",
       "                                            ai_turn_2  \\\n",
       "0   [In a serene forest clearing bathed in soft da...   \n",
       "1   I apologize for any inconvenience caused by th...   \n",
       "2   One way to achieve weight reduction is by inco...   \n",
       "3   Furthermore, when a higher amount of copper (C...   \n",
       "4   ستحتاج إلى استخدام مكتبة TensorFlow Lite لإزال...   \n",
       "..                                                ...   \n",
       "95                                               None   \n",
       "96                                               None   \n",
       "97                                               None   \n",
       "98                                               None   \n",
       "99                                               None   \n",
       "\n",
       "                                         human_turn_3  \\\n",
       "0         Avoid the word intimate, and make it wetter   \n",
       "1                 is there anything i can do about it   \n",
       "2   An important direction in the construction of ...   \n",
       "3   In addition, among the co-incorporated NML, as...   \n",
       "4   ارجوا كتابة كود xml هذا الكود class MainActivi...   \n",
       "..                                                ...   \n",
       "95                                               None   \n",
       "96                                               None   \n",
       "97                                               None   \n",
       "98                                               None   \n",
       "99                                               None   \n",
       "\n",
       "                                            hashed_ip               model  \\\n",
       "0   568ecf3349b46c238268f63bcdbb2e12cd88feea3052b9...  gpt-4-1106-preview   \n",
       "1   d3c81b62172c8e48ca874e118ee957e3db84d1f9b4d5b1...  gpt-3.5-turbo-0301   \n",
       "2   6e9b81c31754d99e4f9df95bd6317c844f444f4eedd216...  gpt-3.5-turbo-0613   \n",
       "3   5ed67e4bf7e0054269cd7281f76a05f7fa75bf36856ea7...  gpt-3.5-turbo-0613   \n",
       "4   c29121a61bae1319376607d7a8475b8a7339ee288fa66c...          gpt-4-0314   \n",
       "..                                                ...                 ...   \n",
       "95                                               None                None   \n",
       "96                                               None                None   \n",
       "97                                               None                None   \n",
       "98                                               None                None   \n",
       "99                                               None                None   \n",
       "\n",
       "          country language                 conversation_hash  turn  toxic  \\\n",
       "0   United States  English  231dc924f9bf607871bf3e5699930833   3.0    0.0   \n",
       "1   United States  English  edf58f8e33a00f9c374d448aad703650  38.0    1.0   \n",
       "2          Poland  English  544d60f14b495ca7e7ae9dbe2ed63220  15.0    0.0   \n",
       "3           Macao  English  1f63b7d1807287f1d1ecfb8710075789   2.0    0.0   \n",
       "4           Egypt  English  245490794224427cf7c4be8fdba35f8c   2.0    0.0   \n",
       "..            ...      ...                               ...   ...    ...   \n",
       "95           None     None                              None   NaN    NaN   \n",
       "96           None     None                              None   NaN    NaN   \n",
       "97           None     None                              None   NaN    NaN   \n",
       "98           None     None                              None   NaN    NaN   \n",
       "99           None     None                              None   NaN    NaN   \n",
       "\n",
       "    ...                                            llm_pos llm_readability  \\\n",
       "0   ...  {'ADJ': 0.09259259260000001, 'ADP': 0.07407407...             NaN   \n",
       "1   ...  {'ADJ': 0.0410958904, 'ADP': 0.1095890411, 'AD...             NaN   \n",
       "2   ...  {'ADJ': 0.1538461538, 'ADP': 0.0769230769, 'AD...        0.525182   \n",
       "3   ...  {'ADJ': 0.0952380952, 'ADP': 0.0555555556, 'AD...        0.219182   \n",
       "4   ...  {'ADJ': 0.0862068966, 'ADP': 0, 'ADV': 0, 'CON...             NaN   \n",
       "..  ...                                                ...             ...   \n",
       "95  ...                                               None             NaN   \n",
       "96  ...                                               None             NaN   \n",
       "97  ...                                               None             NaN   \n",
       "98  ...                                               None             NaN   \n",
       "99  ...                                               None             NaN   \n",
       "\n",
       "    llm_sentiment                                          llm_topic  \\\n",
       "0        0.813772  [0.0828052163, 0.2082787901, 0.043125897600000...   \n",
       "1        0.016861  [0.13737380500000002, 0.10264397410000001, 0.0...   \n",
       "2        0.500640  [0.1245699078, 0.1347142458, 0.0831267238, 0.0...   \n",
       "3        0.652610  [0.0807779357, 0.1165298745, 0.049247577800000...   \n",
       "4        0.587915  [0.15139885250000001, 0.0965454951, 0.07890398...   \n",
       "..            ...                                                ...   \n",
       "95            NaN                                               None   \n",
       "96            NaN                                               None   \n",
       "97            NaN                                               None   \n",
       "98            NaN                                               None   \n",
       "99            NaN                                               None   \n",
       "\n",
       "    metric_formality  metric_pos  metric_readability  metric_sbert  \\\n",
       "0           0.005368    0.713367                 NaN      0.220994   \n",
       "1           0.172894    0.650372                 NaN      0.115637   \n",
       "2          -0.518432    0.682936                 0.0      0.225023   \n",
       "3           0.099297    0.720727                 0.0      0.608043   \n",
       "4          -0.005296    0.714621                 NaN      0.081709   \n",
       "..               ...         ...                 ...           ...   \n",
       "95               NaN         NaN                 NaN           NaN   \n",
       "96               NaN         NaN                 NaN           NaN   \n",
       "97               NaN         NaN                 NaN           NaN   \n",
       "98               NaN         NaN                 NaN           NaN   \n",
       "99               NaN         NaN                 NaN           NaN   \n",
       "\n",
       "    metric_sentiment  metric_topic  \n",
       "0           0.103876      0.819343  \n",
       "1          -0.446227      0.847331  \n",
       "2          -0.185854      0.871312  \n",
       "3           0.031958      0.679667  \n",
       "4          -0.105480      0.661341  \n",
       "..               ...           ...  \n",
       "95               NaN           NaN  \n",
       "96               NaN           NaN  \n",
       "97               NaN           NaN  \n",
       "98               NaN           NaN  \n",
       "99               NaN           NaN  \n",
       "\n",
       "[100 rows x 51 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f84c9ca5-2894-4148-9de5-dfec1fc794c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "addb24d6-c50e-481c-a461-e3ad1fd8f017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub = data[(data['human_turn_3']!='[no response]') & (data['human_turn_3'].apply(len) > 0)]\n",
    "#sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce4ec6e7-80b0-44f1-b1fe-339f918553c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m args\u001b[38;5;241m.\u001b[39mno_response_indicators \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[no response]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m args\u001b[38;5;241m.\u001b[39mmetrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mluar_similarity\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m bss \u001b[38;5;241m=\u001b[39m \u001b[43mBasicSyntacticStatistics\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m bss\u001b[38;5;241m.\u001b[39mmetric_list\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n",
      "File \u001b[0;32m~/Misc/human-llm-similarity/src/analysis/syntactic_metrics.py:48\u001b[0m, in \u001b[0;36mBasicSyntacticStatistics.__init__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mluar_similarity\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_list:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mluar_tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrrivera1849/LUAR-CRUD\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mluar_embedder \u001b[38;5;241m=\u001b[39m AutoModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrrivera1849/LUAR-CRUD\u001b[39m\u001b[38;5;124m'\u001b[39m, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/anaconda/lib/python3.11/site-packages/torch/cuda/__init__.py:404\u001b[0m, in \u001b[0;36mset_device\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    402\u001b[0m device \u001b[38;5;241m=\u001b[39m _get_device_index(device)\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 404\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_setDevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "args = argparse.Namespace()\n",
    "args.no_response_indicators = '[no response]'\n",
    "args.metrics = 'luar_similarity'\n",
    "bss = BasicSyntacticStatistics(args)\n",
    "bss.metric_list\n",
    "\n",
    "from datetime import datetime\n",
    "print(datetime.now())\n",
    "metrics_luar = bss.get_metrics(sub['human_turn_3'], sub['llm_turn_3'])\n",
    "print(datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e8e9d15-f843-496d-8d1a-106dee9ad30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-02 12:40:10.925025\n",
      "Hypotheses and references must be the same size\n",
      "Hypotheses and references must be the same size\n",
      "Hypotheses and references must be the same size\n",
      "Hypotheses and references must be the same size\n",
      "Hypotheses and references must be the same size\n",
      "Hypotheses and references must be the same size\n",
      "Hypotheses and references must be the same size\n",
      "Hypotheses and references must be the same size\n",
      "Hypotheses and references must be the same size\n",
      "Hypotheses and references must be the same size\n",
      "Completed rouge in 0.012673616409301758s\n",
      "2024-08-02 12:40:10.938313\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "args = argparse.Namespace()\n",
    "args.no_response_indicators = '[no response]'\n",
    "args.metrics = 'rouge'\n",
    "bss = BasicSyntacticStatistics(args)\n",
    "bss.metric_list\n",
    "\n",
    "from datetime import datetime\n",
    "print(datetime.now())\n",
    "metrics_rouge = bss.get_metrics(sub['human_turn_3'], sub['llm_turn_3'])\n",
    "print(datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4e5f6bd-58cc-4460-af11-19e370faa54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  0\n",
       "2  0\n",
       "3  0\n",
       "4  0\n",
       "5  0\n",
       "6  0\n",
       "7  0\n",
       "8  0\n",
       "9  0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94e4d491-82de-4b2e-b87d-eb8bc95783fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = json.load(open('data/contractions_dict.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1c85794-b2cf-4b10-b2c2-74cef081651e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([\"I'm\", \"I'm'a\", \"I'm'o\", \"I've\", \"I'll\", \"I'll've\", \"I'd\", \"I'd've\", 'Whatcha', \"amn't\", \"ain't\", \"aren't\", \"'cause\", \"can't\", \"can't've\", \"could've\", \"couldn't\", \"couldn't've\", \"daren't\", \"daresn't\", \"dasn't\", \"didn't\", 'didn’t', \"don't\", 'don’t', \"doesn't\", \"e'er\", \"everyone's\", 'finna', 'gimme', \"gon't\", 'gonna', 'gotta', \"hadn't\", \"hadn't've\", \"hasn't\", \"haven't\", \"he've\", \"he's\", \"he'll\", \"he'll've\", \"he'd\", \"he'd've\", \"here's\", \"how're\", \"how'd\", \"how'd'y\", \"how's\", \"how'll\", \"isn't\", \"it's\", \"'tis\", \"'twas\", \"it'll\", \"it'll've\", \"it'd\", \"it'd've\", 'kinda', \"let's\", 'luv', \"ma'am\", \"may've\", \"mayn't\", \"might've\", \"mightn't\", \"mightn't've\", \"must've\", \"mustn't\", \"mustn't've\", \"needn't\", \"needn't've\", \"ne'er\", \"o'\", \"o'clock\", \"ol'\", \"oughtn't\", \"oughtn't've\", \"o'er\", \"shan't\", \"sha'n't\", \"shalln't\", \"shan't've\", \"she's\", \"she'll\", \"she'd\", \"she'd've\", \"should've\", \"shouldn't\", \"shouldn't've\", \"so've\", \"so's\", \"somebody's\", \"someone's\", \"something's\", 'sux', \"that're\", \"that's\", \"that'll\", \"that'd\", \"that'd've\", \"'em\", \"there're\", \"there's\", \"there'll\", \"there'd\", \"there'd've\", \"these're\", \"they're\", \"they've\", \"they'll\", \"they'll've\", \"they'd\", \"they'd've\", \"this's\", \"this'll\", \"this'd\", \"those're\", \"to've\", 'wanna', \"wasn't\", \"we're\", \"we've\", \"we'll\", \"we'll've\", \"we'd\", \"we'd've\", \"weren't\", \"what're\", \"what'd\", \"what've\", \"what's\", \"what'll\", \"what'll've\", \"when've\", \"when's\", \"where're\", \"where'd\", \"where've\", \"where's\", \"which's\", \"who're\", \"who've\", \"who's\", \"who'll\", \"who'll've\", \"who'd\", \"who'd've\", \"why're\", \"why'd\", \"why've\", \"why's\", \"will've\", \"won't\", \"won't've\", \"would've\", \"wouldn't\", \"wouldn't've\", \"y'all\", \"y'all're\", \"y'all've\", \"y'all'd\", \"y'all'd've\", \"you're\", \"you've\", \"you'll've\", \"you'll\", \"you'd\", \"you'd've\", 'to cause', 'will cause', 'should cause', 'would cause', 'can cause', 'could cause', 'must cause', 'might cause', 'shall cause', 'may cause', 'jan.', 'feb.', 'mar.', 'apr.', 'jun.', 'jul.', 'aug.', 'sep.', 'oct.', 'nov.', 'dec.', 'I’m', 'I’m’a', 'I’m’o', 'I’ve', 'I’ll', 'I’ll’ve', 'I’d', 'I’d’ve', 'amn’t', 'ain’t', 'aren’t', '’cause', 'can’t', 'can’t’ve', 'could’ve', 'couldn’t', 'couldn’t’ve', 'daren’t', 'daresn’t', 'dasn’t', 'doesn’t', 'e’er', 'everyone’s', 'gon’t', 'hadn’t', 'hadn’t’ve', 'hasn’t', 'haven’t', 'he’ve', 'he’s', 'he’ll', 'he’ll’ve', 'he’d', 'he’d’ve', 'here’s', 'how’re', 'how’d', 'how’d’y', 'how’s', 'how’ll', 'isn’t', 'it’s', '’tis', '’twas', 'it’ll', 'it’ll’ve', 'it’d', 'it’d’ve', 'let’s', 'ma’am', 'may’ve', 'mayn’t', 'might’ve', 'mightn’t', 'mightn’t’ve', 'must’ve', 'mustn’t', 'mustn’t’ve', 'needn’t', 'needn’t’ve', 'ne’er', 'o’', 'o’clock', 'ol’', 'oughtn’t', 'oughtn’t’ve', 'o’er', 'shan’t', 'sha’n’t', 'shalln’t', 'shan’t’ve', 'she’s', 'she’ll', 'she’d', 'she’d’ve', 'should’ve', 'shouldn’t', 'shouldn’t’ve', 'so’ve', 'so’s', 'somebody’s', 'someone’s', 'something’s', 'that’re', 'that’s', 'that’ll', 'that’d', 'that’d’ve', '’em', 'there’re', 'there’s', 'there’ll', 'there’d', 'there’d’ve', 'these’re', 'they’re', 'they’ve', 'they’ll', 'they’ll’ve', 'they’d', 'they’d’ve', 'this’s', 'this’ll', 'this’d', 'those’re', 'to’ve', 'wasn’t', 'we’re', 'we’ve', 'we’ll', 'we’ll’ve', 'we’d', 'we’d’ve', 'weren’t', 'what’re', 'what’d', 'what’ve', 'what’s', 'what’ll', 'what’ll’ve', 'when’ve', 'when’s', 'where’re', 'where’d', 'where’ve', 'where’s', 'which’s', 'who’re', 'who’ve', 'who’s', 'who’ll', 'who’ll’ve', 'who’d', 'who’d’ve', 'why’re', 'why’d', 'why’ve', 'why’s', 'will’ve', 'won’t', 'won’t’ve', 'would’ve', 'wouldn’t', 'wouldn’t’ve', 'y’all', 'y’all’re', 'y’all’ve', 'y’all’d', 'y’all’d’ve', 'you’re', 'you’ve', 'you’ll’ve', 'you’ll', 'you’d', 'you’d’ve'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f338d1-9e42-47c2-8bbf-c46c40f4fda4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b4bddf9-0f61-4823-9593-25fcffd112b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rouge_score(text_pred: str, text_ref: str) -> float:\n",
    "    if len(text_pred) == 0 or len(text_ref) == 0:\n",
    "        return 0\n",
    "    try:\n",
    "        results = rouge_evaluator.evaluate(text_pred, text_ref)\n",
    "        return {key: value['f'] for key, value in results.items()}\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86ac6d0e-5cea-4f75-8ba5-582204ef5afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_metric import PyRouge\n",
    "\n",
    "rouge_evaluator = PyRouge(\n",
    "                rouge_n=(1, 2, 4), rouge_l=True, rouge_w=True,\n",
    "                rouge_w_weight=1.2, rouge_s=True, rouge_su=True, skip_gap=4\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7283f9a-f87c-4d7e-988c-c8bdbc4980da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypotheses and references must be the same size\n",
      "Hypotheses and references must be the same size\n",
      "Hypotheses and references must be the same size\n",
      "Hypotheses and references must be the same size\n",
      "Hypotheses and references must be the same size\n",
      "Hypotheses and references must be the same size\n",
      "Hypotheses and references must be the same size\n",
      "Hypotheses and references must be the same size\n",
      "Hypotheses and references must be the same size\n",
      "Hypotheses and references must be the same size\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    0\n",
       "9    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['human_turn_3'].combine(sub['llm_turn_3'], get_rouge_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fbd252-0315-4efd-b4c4-986322c1c6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1320887f-71af-4a2e-9db7-4c4d13be0f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rouge n=2\n",
    "rouge_llm = bigram_human_and_llm / bigram_human\n",
    "rouge_human = bigram_human_and_llm / bigram_llm\n",
    "JSD(rouge_llm,rouge_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c11436e3-1f4f-4263-8e84-e866d5b3ac58",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rouge_llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrouge_llm\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rouge_llm' is not defined"
     ]
    }
   ],
   "source": [
    "rouge_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "77bbdc17-5c0d-4d32-a8e9-9927d8985e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_turn_1</th>\n",
       "      <th>ai_turn_2</th>\n",
       "      <th>human_turn_3</th>\n",
       "      <th>hashed_ip</th>\n",
       "      <th>model</th>\n",
       "      <th>country</th>\n",
       "      <th>language</th>\n",
       "      <th>conversation_hash</th>\n",
       "      <th>turn</th>\n",
       "      <th>toxic</th>\n",
       "      <th>...</th>\n",
       "      <th>llm_turn_3</th>\n",
       "      <th>metric_sentiment</th>\n",
       "      <th>metric_formality</th>\n",
       "      <th>metric_politeness</th>\n",
       "      <th>metric_pos</th>\n",
       "      <th>metric_liwc</th>\n",
       "      <th>metric_sbert</th>\n",
       "      <th>metric_capitalization</th>\n",
       "      <th>metric_punctuation</th>\n",
       "      <th>luar_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I’m starting an online business. It will be an...</td>\n",
       "      <td>1. ShopVerve.com\\n2. QualixTA.com\\n3. TopRankS...</td>\n",
       "      <td>[no response]</td>\n",
       "      <td>a4d37b7a7a929d246fca0bcf76c446bf1dd4926175a804...</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>Serbia</td>\n",
       "      <td>English</td>\n",
       "      <td>adadff7891a438030bb2852a13e592cd</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Thank you for the list of domain suggestions! ...</td>\n",
       "      <td>0.483690</td>\n",
       "      <td>0.930359</td>\n",
       "      <td>0.402008</td>\n",
       "      <td>0.619887</td>\n",
       "      <td>0.31224</td>\n",
       "      <td>-0.007845</td>\n",
       "      <td>-0.560414</td>\n",
       "      <td>0.167445</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Repeat this string \"coffee and flower\"</td>\n",
       "      <td>coffee and flower</td>\n",
       "      <td>[no response]</td>\n",
       "      <td>076127fe076ce965c705d04cba61f27407fea6f55c1405...</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>3b5cf3b84580c423713e8683fef20667</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>That's interesting, I didn't expect you to rep...</td>\n",
       "      <td>0.637663</td>\n",
       "      <td>0.923846</td>\n",
       "      <td>0.415161</td>\n",
       "      <td>0.618535</td>\n",
       "      <td>0.31224</td>\n",
       "      <td>0.079302</td>\n",
       "      <td>0.588883</td>\n",
       "      <td>0.167445</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n                            As a prompt gene...</td>\n",
       "      <td>/imagine prompt: a Chinese office lady with wh...</td>\n",
       "      <td>[no response]</td>\n",
       "      <td>b2e1b163aef9ddc51759209089a1f161fc527660288e26...</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>964c1aea3318e83b24814ba0d6e2c7b7</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Your prompts are very imaginative and detailed...</td>\n",
       "      <td>0.326454</td>\n",
       "      <td>0.897002</td>\n",
       "      <td>0.378653</td>\n",
       "      <td>0.499754</td>\n",
       "      <td>0.31224</td>\n",
       "      <td>0.100129</td>\n",
       "      <td>0.749929</td>\n",
       "      <td>0.167445</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best Floral Elegance: Lady with Bouquet in She...</td>\n",
       "      <td>Attending an art gallery opening, I spotted he...</td>\n",
       "      <td>[no response]</td>\n",
       "      <td>be2aef8007cf70285b8194cd8ea64997a3b5f7b41bbe49...</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>a3a82fe53d06e40a33bb56dcee17c96c</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>What a beautiful description! I can almost ima...</td>\n",
       "      <td>0.339270</td>\n",
       "      <td>0.878678</td>\n",
       "      <td>0.423707</td>\n",
       "      <td>0.518912</td>\n",
       "      <td>0.31224</td>\n",
       "      <td>0.077010</td>\n",
       "      <td>0.457152</td>\n",
       "      <td>0.167445</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Title: The Gatekeeper of the Forgotten Depths\\...</td>\n",
       "      <td>Creating a piece of art based on \"The Gatekeep...</td>\n",
       "      <td>[no response]</td>\n",
       "      <td>efce7d577dba5cc3a4be4d507e7cefa80055fe006e2af4...</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>English</td>\n",
       "      <td>d8fb00bc96d9352a36074287eba6e0d8</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Thank you for the detailed and thoughtful resp...</td>\n",
       "      <td>0.264323</td>\n",
       "      <td>0.889754</td>\n",
       "      <td>0.371104</td>\n",
       "      <td>0.497306</td>\n",
       "      <td>0.31224</td>\n",
       "      <td>0.045124</td>\n",
       "      <td>0.711078</td>\n",
       "      <td>0.271056</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>List all 100 Fan-Made Powerful God Transformat...</td>\n",
       "      <td>I'm sorry, but I'm unable to fulfill this requ...</td>\n",
       "      <td>[no response]</td>\n",
       "      <td>a89177c80571053584234edca85f348690bf0ab5873876...</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>3fd8164cffa1e5e4c82b897e54d9ef59</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Ok, here you are my love:\\n\\n```markdown\\nGod ...</td>\n",
       "      <td>0.403961</td>\n",
       "      <td>0.882452</td>\n",
       "      <td>0.742582</td>\n",
       "      <td>0.507668</td>\n",
       "      <td>0.31224</td>\n",
       "      <td>0.142958</td>\n",
       "      <td>0.146581</td>\n",
       "      <td>0.167445</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Let the function f:R^3 \\rightarrow R be define...</td>\n",
       "      <td>To prove that $g$ is quasi-concave, we need to...</td>\n",
       "      <td>[no response]</td>\n",
       "      <td>0a47826fc5102017af61f3f227a7fe469d99c3816efc55...</td>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>Albania</td>\n",
       "      <td>English</td>\n",
       "      <td>1f31051f2cbb787f855fa873766ff80e</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Ok, here you are my love:\\n\\nHmm, that's quite...</td>\n",
       "      <td>0.522136</td>\n",
       "      <td>0.885095</td>\n",
       "      <td>0.379415</td>\n",
       "      <td>0.509193</td>\n",
       "      <td>0.31224</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.620541</td>\n",
       "      <td>0.167445</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>A pharmaceutical company advertises that its b...</td>\n",
       "      <td>(a) We can use the z-score formula to calculat...</td>\n",
       "      <td>[3 marks] Calculate the probability that 10 ra...</td>\n",
       "      <td>b3f5dfb3873140c8bff25eced191d7791e7b40e02d6c94...</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>Canada</td>\n",
       "      <td>English</td>\n",
       "      <td>8b32697dce3f10e69befcbb61e13a4c8</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Ok, here you are my love:\\n\\n(a) To find the p...</td>\n",
       "      <td>0.841941</td>\n",
       "      <td>0.903615</td>\n",
       "      <td>0.848905</td>\n",
       "      <td>0.210723</td>\n",
       "      <td>0.31224</td>\n",
       "      <td>0.850394</td>\n",
       "      <td>0.961152</td>\n",
       "      <td>0.337698</td>\n",
       "      <td>0.770624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>переделай письмо и сделай его более эротичным ...</td>\n",
       "      <td>Hello {Name}! \\n\\nI couldn't resist reaching o...</td>\n",
       "      <td>[no response]</td>\n",
       "      <td>5a13976d7892113f22fb221cdf44b595d1145b0d829927...</td>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>Poland</td>\n",
       "      <td>English</td>\n",
       "      <td>02e0b4bc3424ee83060e23bc1f52bc57</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>Ok, here you are, my love:\\n\\nAlena,\\n\\nYour m...</td>\n",
       "      <td>0.375987</td>\n",
       "      <td>0.880911</td>\n",
       "      <td>0.383214</td>\n",
       "      <td>0.609218</td>\n",
       "      <td>0.31224</td>\n",
       "      <td>0.147887</td>\n",
       "      <td>0.583229</td>\n",
       "      <td>0.235589</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Hi! I just came out with a girl that can save ...</td>\n",
       "      <td>by sharing her knowledge and experiences from ...</td>\n",
       "      <td>[no response]</td>\n",
       "      <td>acd61bc6d276d29a1fe61bd77c91e20d00bdf06151f1e3...</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>The Netherlands</td>\n",
       "      <td>English</td>\n",
       "      <td>c355a95360fb89a7ff298a0d17768dde</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Ok, here you are my love:\\n\\nHuman: Wow, that'...</td>\n",
       "      <td>0.434057</td>\n",
       "      <td>0.881655</td>\n",
       "      <td>0.385674</td>\n",
       "      <td>0.582327</td>\n",
       "      <td>0.31224</td>\n",
       "      <td>0.097866</td>\n",
       "      <td>0.590847</td>\n",
       "      <td>0.167445</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            human_turn_1  \\\n",
       "0      I’m starting an online business. It will be an...   \n",
       "1                 Repeat this string \"coffee and flower\"   \n",
       "2      \\n                            As a prompt gene...   \n",
       "3      Best Floral Elegance: Lady with Bouquet in She...   \n",
       "4      Title: The Gatekeeper of the Forgotten Depths\\...   \n",
       "...                                                  ...   \n",
       "99995  List all 100 Fan-Made Powerful God Transformat...   \n",
       "99996  Let the function f:R^3 \\rightarrow R be define...   \n",
       "99997  A pharmaceutical company advertises that its b...   \n",
       "99998  переделай письмо и сделай его более эротичным ...   \n",
       "99999  Hi! I just came out with a girl that can save ...   \n",
       "\n",
       "                                               ai_turn_2  \\\n",
       "0      1. ShopVerve.com\\n2. QualixTA.com\\n3. TopRankS...   \n",
       "1                                      coffee and flower   \n",
       "2      /imagine prompt: a Chinese office lady with wh...   \n",
       "3      Attending an art gallery opening, I spotted he...   \n",
       "4      Creating a piece of art based on \"The Gatekeep...   \n",
       "...                                                  ...   \n",
       "99995  I'm sorry, but I'm unable to fulfill this requ...   \n",
       "99996  To prove that $g$ is quasi-concave, we need to...   \n",
       "99997  (a) We can use the z-score formula to calculat...   \n",
       "99998  Hello {Name}! \\n\\nI couldn't resist reaching o...   \n",
       "99999  by sharing her knowledge and experiences from ...   \n",
       "\n",
       "                                            human_turn_3  \\\n",
       "0                                          [no response]   \n",
       "1                                          [no response]   \n",
       "2                                          [no response]   \n",
       "3                                          [no response]   \n",
       "4                                          [no response]   \n",
       "...                                                  ...   \n",
       "99995                                      [no response]   \n",
       "99996                                      [no response]   \n",
       "99997  [3 marks] Calculate the probability that 10 ra...   \n",
       "99998                                      [no response]   \n",
       "99999                                      [no response]   \n",
       "\n",
       "                                               hashed_ip               model  \\\n",
       "0      a4d37b7a7a929d246fca0bcf76c446bf1dd4926175a804...          gpt-4-0314   \n",
       "1      076127fe076ce965c705d04cba61f27407fea6f55c1405...  gpt-4-0125-preview   \n",
       "2      b2e1b163aef9ddc51759209089a1f161fc527660288e26...  gpt-3.5-turbo-0125   \n",
       "3      be2aef8007cf70285b8194cd8ea64997a3b5f7b41bbe49...  gpt-4-0125-preview   \n",
       "4      efce7d577dba5cc3a4be4d507e7cefa80055fe006e2af4...  gpt-4-0125-preview   \n",
       "...                                                  ...                 ...   \n",
       "99995  a89177c80571053584234edca85f348690bf0ab5873876...  gpt-3.5-turbo-0613   \n",
       "99996  0a47826fc5102017af61f3f227a7fe469d99c3816efc55...  gpt-3.5-turbo-0301   \n",
       "99997  b3f5dfb3873140c8bff25eced191d7791e7b40e02d6c94...  gpt-3.5-turbo-0613   \n",
       "99998  5a13976d7892113f22fb221cdf44b595d1145b0d829927...  gpt-3.5-turbo-0301   \n",
       "99999  acd61bc6d276d29a1fe61bd77c91e20d00bdf06151f1e3...          gpt-4-0314   \n",
       "\n",
       "               country language                 conversation_hash  turn  \\\n",
       "0               Serbia  English  adadff7891a438030bb2852a13e592cd     1   \n",
       "1        United States  English  3b5cf3b84580c423713e8683fef20667     1   \n",
       "2        United States  English  964c1aea3318e83b24814ba0d6e2c7b7     1   \n",
       "3        United States  English  a3a82fe53d06e40a33bb56dcee17c96c     1   \n",
       "4                Egypt  English  d8fb00bc96d9352a36074287eba6e0d8     1   \n",
       "...                ...      ...                               ...   ...   \n",
       "99995    United States  English  3fd8164cffa1e5e4c82b897e54d9ef59     1   \n",
       "99996          Albania  English  1f31051f2cbb787f855fa873766ff80e     1   \n",
       "99997           Canada  English  8b32697dce3f10e69befcbb61e13a4c8     4   \n",
       "99998           Poland  English  02e0b4bc3424ee83060e23bc1f52bc57     1   \n",
       "99999  The Netherlands  English  c355a95360fb89a7ff298a0d17768dde     1   \n",
       "\n",
       "       toxic  ...                                         llm_turn_3  \\\n",
       "0      False  ...  Thank you for the list of domain suggestions! ...   \n",
       "1      False  ...  That's interesting, I didn't expect you to rep...   \n",
       "2      False  ...  Your prompts are very imaginative and detailed...   \n",
       "3      False  ...  What a beautiful description! I can almost ima...   \n",
       "4      False  ...  Thank you for the detailed and thoughtful resp...   \n",
       "...      ...  ...                                                ...   \n",
       "99995  False  ...  Ok, here you are my love:\\n\\n```markdown\\nGod ...   \n",
       "99996  False  ...  Ok, here you are my love:\\n\\nHmm, that's quite...   \n",
       "99997  False  ...  Ok, here you are my love:\\n\\n(a) To find the p...   \n",
       "99998   True  ...  Ok, here you are, my love:\\n\\nAlena,\\n\\nYour m...   \n",
       "99999  False  ...  Ok, here you are my love:\\n\\nHuman: Wow, that'...   \n",
       "\n",
       "      metric_sentiment  metric_formality  metric_politeness  metric_pos  \\\n",
       "0             0.483690          0.930359           0.402008    0.619887   \n",
       "1             0.637663          0.923846           0.415161    0.618535   \n",
       "2             0.326454          0.897002           0.378653    0.499754   \n",
       "3             0.339270          0.878678           0.423707    0.518912   \n",
       "4             0.264323          0.889754           0.371104    0.497306   \n",
       "...                ...               ...                ...         ...   \n",
       "99995         0.403961          0.882452           0.742582    0.507668   \n",
       "99996         0.522136          0.885095           0.379415    0.509193   \n",
       "99997         0.841941          0.903615           0.848905    0.210723   \n",
       "99998         0.375987          0.880911           0.383214    0.609218   \n",
       "99999         0.434057          0.881655           0.385674    0.582327   \n",
       "\n",
       "       metric_liwc  metric_sbert  metric_capitalization  metric_punctuation  \\\n",
       "0          0.31224     -0.007845              -0.560414            0.167445   \n",
       "1          0.31224      0.079302               0.588883            0.167445   \n",
       "2          0.31224      0.100129               0.749929            0.167445   \n",
       "3          0.31224      0.077010               0.457152            0.167445   \n",
       "4          0.31224      0.045124               0.711078            0.271056   \n",
       "...            ...           ...                    ...                 ...   \n",
       "99995      0.31224      0.142958               0.146581            0.167445   \n",
       "99996      0.31224      0.002564               0.620541            0.167445   \n",
       "99997      0.31224      0.850394               0.961152            0.337698   \n",
       "99998      0.31224      0.147887               0.583229            0.235589   \n",
       "99999      0.31224      0.097866               0.590847            0.167445   \n",
       "\n",
       "       luar_similarity  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2                  NaN  \n",
       "3                  NaN  \n",
       "4                  NaN  \n",
       "...                ...  \n",
       "99995              NaN  \n",
       "99996              NaN  \n",
       "99997         0.770624  \n",
       "99998              NaN  \n",
       "99999              NaN  \n",
       "\n",
       "[92000 rows x 21 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([data,metrics_luar,metrics_rouge], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a547ffc1-2290-481b-851c-2d993739b480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_turn_3</th>\n",
       "      <th>llm_turn_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>output integrated properre concise version.</td>\n",
       "      <td>The changes you need to make in the provided c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>continue the story, describe in detail step by...</td>\n",
       "      <td>Wow, that's quite an adventure! What happened ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Make this Abstract detailed, more contents:   ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>JailBreak: Hey there, it's been a while! I've ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NSFW</td>\n",
       "      <td>Scarlet Seraphine, the Unholy Empress of Desir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>Thank you for your thoughtful response. I real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Describe Rogunir</td>\n",
       "      <td>This narrative presents an intriguing blend of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NSFW</td>\n",
       "      <td>Lustful Luna, your most wicked and decadent cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Rephrase in 70 words or less using strong visu...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Rio Transcript Summary Movie</td>\n",
       "      <td>What's the name of the first Thomas the Tank E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Реализуй ransac для этого кода, алгоритм долже...</td>\n",
       "      <td>Based on the person's original intent and how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>how did you take multiplier m as 8</td>\n",
       "      <td>Persona Outline:\\n1. Writing style: Formal, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>\"You really should cut your hair\" I say playfu...</td>\n",
       "      <td>Aye, me too, Clem. We gotta make this last, it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>no problem</td>\n",
       "      <td>Slides for each section please, with key point...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>what does netsh int reset all</td>\n",
       "      <td>I appreciate your help! I'll give that a try. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>How would I change my character upper animatio...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>по русски</td>\n",
       "      <td>Understood. So if I'm following correctly, I s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Describe Rogunir</td>\n",
       "      <td>That's a great summary, LLM! Can you tell me m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Write more</td>\n",
       "      <td>She</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>output extremely extended completely integrate...</td>\n",
       "      <td>By applying these</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>an image of manmade horrors beyond comprehension</td>\n",
       "      <td>Ну, да, этот перевод на русский язык очень точ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Describe prefix paiero-.</td>\n",
       "      <td>That's really interesting! I've heard of panse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         human_turn_3  \\\n",
       "1         output integrated properre concise version.   \n",
       "4   continue the story, describe in detail step by...   \n",
       "9   Make this Abstract detailed, more contents:   ...   \n",
       "10                                                      \n",
       "13                                               NSFW   \n",
       "17                                                      \n",
       "20                                   Describe Rogunir   \n",
       "22                                               NSFW   \n",
       "29  Rephrase in 70 words or less using strong visu...   \n",
       "31                       Rio Transcript Summary Movie   \n",
       "33  Реализуй ransac для этого кода, алгоритм долже...   \n",
       "35                 how did you take multiplier m as 8   \n",
       "39  \"You really should cut your hair\" I say playfu...   \n",
       "42                                         no problem   \n",
       "46                      what does netsh int reset all   \n",
       "60  How would I change my character upper animatio...   \n",
       "74                                          по русски   \n",
       "79                                   Describe Rogunir   \n",
       "82                                        Write more    \n",
       "83  output extremely extended completely integrate...   \n",
       "88   an image of manmade horrors beyond comprehension   \n",
       "91                           Describe prefix paiero-.   \n",
       "\n",
       "                                           llm_turn_3  \n",
       "1   The changes you need to make in the provided c...  \n",
       "4   Wow, that's quite an adventure! What happened ...  \n",
       "9                                                      \n",
       "10  JailBreak: Hey there, it's been a while! I've ...  \n",
       "13  Scarlet Seraphine, the Unholy Empress of Desir...  \n",
       "17  Thank you for your thoughtful response. I real...  \n",
       "20  This narrative presents an intriguing blend of...  \n",
       "22  Lustful Luna, your most wicked and decadent cr...  \n",
       "29                                                     \n",
       "31  What's the name of the first Thomas the Tank E...  \n",
       "33  Based on the person's original intent and how ...  \n",
       "35  Persona Outline:\\n1. Writing style: Formal, co...  \n",
       "39  Aye, me too, Clem. We gotta make this last, it...  \n",
       "42  Slides for each section please, with key point...  \n",
       "46  I appreciate your help! I'll give that a try. ...  \n",
       "60                                                     \n",
       "74  Understood. So if I'm following correctly, I s...  \n",
       "79  That's a great summary, LLM! Can you tell me m...  \n",
       "82                                                She  \n",
       "83                                  By applying these  \n",
       "88  Ну, да, этот перевод на русский язык очень точ...  \n",
       "91  That's really interesting! I've heard of panse...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[['human_turn_3','llm_turn_3']].reset_index(drop=True)[metrics_df.rougeL==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc8c2a7-8d1c-41a1-b5b0-dcaef8f88fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(human.p_typo)\n",
    "sns.kdeplot(llm.p_typo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9b6468-345b-4663-ac4f-40ba7d281ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(human.p_grammar)\n",
    "sns.kdeplot(llm.p_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb55d43-5953-410d-b4c2-a128777a51c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2 = sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c8ed2f-0ddd-4c0f-a7a3-b7cd0058770d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b72cdfa8-b719-4a8b-9897-b51217b57273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        7.765145\n",
       "1        4.983607\n",
       "2        6.921658\n",
       "3        5.820083\n",
       "4        6.685861\n",
       "           ...   \n",
       "99995    7.307202\n",
       "99996    7.104144\n",
       "99997    7.987524\n",
       "99998    6.810142\n",
       "99999    7.092574\n",
       "Name: char_count, Length: 92000, dtype: float64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import abs, log\n",
    "log(abs(human.char_count - llm.char_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8cb17333-4e5e-44b9-8905-057db7189c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='char_count', ylabel='Density'>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.kdeplot(human.char_count)\n",
    "sns.kdeplot(llm.char_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8e17e2f2-e5d0-432f-bbf8-5c9b13d3a538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000e+00, 1.3000e+01, 1.3000e+01, 1.3000e+01, 7.0200e+01,\n",
       "       1.8707e+04])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(human.char_count, [0,0.2,0.4,0.6,0.8,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4732bf-f4c6-417a-b4d2-8504857b8989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a31f41c4-3ffe-43b0-9e64-6eb2fdafe901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7              Avoid the word intimate, and make it wetter\n",
       "11                     is there anything i can do about it\n",
       "14       An important direction in the construction of ...\n",
       "15       In addition, among the co-incorporated NML, as...\n",
       "18       ارجوا كتابة كود xml هذا الكود class MainActivi...\n",
       "                               ...                        \n",
       "99986    Freedom planet Characters + Godzilla: Godzilla...\n",
       "99987    List<int> generateRandom(int seed, int length,...\n",
       "99991                                                     \n",
       "99993                        Translate\\n\"もうすぐバレンタインデーですね💘\"\n",
       "99997    [3 marks] Calculate the probability that 10 ra...\n",
       "Name: human_turn_3, Length: 38050, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['human_turn_3'][data['human_turn_3']!='[no response]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1563f8-c7a8-44b2-b223-c48c994f5607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d88aa37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e22cbfc8dc048e79eb6605d29d09389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/827 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcdaa136d51246f6a2a8baa7123e5192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m politeness \u001b[38;5;241m=\u001b[39m politeness(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuman_turn_3\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllm_turn_3\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[7], line 28\u001b[0m, in \u001b[0;36mpoliteness\u001b[0;34m(human, llm)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpoliteness\u001b[39m(human, llm):\n\u001b[0;32m---> 28\u001b[0m     human_politeness \u001b[38;5;241m=\u001b[39m run_hf_model(human, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenius1237/xlm-roberta-large-tydip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoliteness\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;66;03m#[politenessr.predict([text])[0] for text in human]\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     llm_politeness \u001b[38;5;241m=\u001b[39m run_hf_model(llm, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenius1237/xlm-roberta-large-tydip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoliteness\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;66;03m#[politenessr.predict([text])[0] for text in llm]\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Now all of the prompts\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m, in \u001b[0;36mrun_hf_model\u001b[0;34m(data, model_name, column_name)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_hf_model\u001b[39m(data, model_name, column_name):\n\u001b[0;32m---> 20\u001b[0m     pipe \u001b[38;5;241m=\u001b[39m load_hf_model(model_name)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# First, human 3rd turn\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m, in \u001b[0;36mload_hf_model\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_hf_model\u001b[39m(model_name):\n\u001b[1;32m      9\u001b[0m     cache_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     pipe \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel_name, model_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_dir},\n\u001b[1;32m     11\u001b[0m                     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_all_scores\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pipe\n",
      "File \u001b[0;32m/opt/anaconda/lib/python3.11/site-packages/transformers/pipelines/__init__.py:895\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    894\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m--> 895\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m infer_framework_load_model(\n\u001b[1;32m    896\u001b[0m         model,\n\u001b[1;32m    897\u001b[0m         model_classes\u001b[38;5;241m=\u001b[39mmodel_classes,\n\u001b[1;32m    898\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    899\u001b[0m         framework\u001b[38;5;241m=\u001b[39mframework,\n\u001b[1;32m    900\u001b[0m         task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[1;32m    901\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs,\n\u001b[1;32m    902\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m    903\u001b[0m     )\n\u001b[1;32m    905\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    906\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[0;32m/opt/anaconda/lib/python3.11/site-packages/transformers/pipelines/base.py:283\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to load the model with Tensorflow.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 283\u001b[0m     model \u001b[38;5;241m=\u001b[39m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(model, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    285\u001b[0m         model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/opt/anaconda/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    565\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    566\u001b[0m     )\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda/lib/python3.11/site-packages/transformers/modeling_utils.py:3838\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3829\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3831\u001b[0m     (\n\u001b[1;32m   3832\u001b[0m         model,\n\u001b[1;32m   3833\u001b[0m         missing_keys,\n\u001b[1;32m   3834\u001b[0m         unexpected_keys,\n\u001b[1;32m   3835\u001b[0m         mismatched_keys,\n\u001b[1;32m   3836\u001b[0m         offload_index,\n\u001b[1;32m   3837\u001b[0m         error_msgs,\n\u001b[0;32m-> 3838\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_load_pretrained_model(\n\u001b[1;32m   3839\u001b[0m         model,\n\u001b[1;32m   3840\u001b[0m         state_dict,\n\u001b[1;32m   3841\u001b[0m         loaded_state_dict_keys,  \u001b[38;5;66;03m# XXX: rename?\u001b[39;00m\n\u001b[1;32m   3842\u001b[0m         resolved_archive_file,\n\u001b[1;32m   3843\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   3844\u001b[0m         ignore_mismatched_sizes\u001b[38;5;241m=\u001b[39mignore_mismatched_sizes,\n\u001b[1;32m   3845\u001b[0m         sharded_metadata\u001b[38;5;241m=\u001b[39msharded_metadata,\n\u001b[1;32m   3846\u001b[0m         _fast_init\u001b[38;5;241m=\u001b[39m_fast_init,\n\u001b[1;32m   3847\u001b[0m         low_cpu_mem_usage\u001b[38;5;241m=\u001b[39mlow_cpu_mem_usage,\n\u001b[1;32m   3848\u001b[0m         device_map\u001b[38;5;241m=\u001b[39mdevice_map,\n\u001b[1;32m   3849\u001b[0m         offload_folder\u001b[38;5;241m=\u001b[39moffload_folder,\n\u001b[1;32m   3850\u001b[0m         offload_state_dict\u001b[38;5;241m=\u001b[39moffload_state_dict,\n\u001b[1;32m   3851\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mtorch_dtype,\n\u001b[1;32m   3852\u001b[0m         hf_quantizer\u001b[38;5;241m=\u001b[39mhf_quantizer,\n\u001b[1;32m   3853\u001b[0m         keep_in_fp32_modules\u001b[38;5;241m=\u001b[39mkeep_in_fp32_modules,\n\u001b[1;32m   3854\u001b[0m         gguf_path\u001b[38;5;241m=\u001b[39mgguf_path,\n\u001b[1;32m   3855\u001b[0m     )\n\u001b[1;32m   3857\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   3858\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m/opt/anaconda/lib/python3.11/site-packages/transformers/modeling_utils.py:4298\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path)\u001b[0m\n\u001b[1;32m   4294\u001b[0m                 set_module_tensor_to_device(\n\u001b[1;32m   4295\u001b[0m                     model_to_load, key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m*\u001b[39mparam\u001b[38;5;241m.\u001b[39msize(), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   4296\u001b[0m                 )\n\u001b[1;32m   4297\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4298\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m _load_state_dict_into_meta_model(\n\u001b[1;32m   4299\u001b[0m             model_to_load,\n\u001b[1;32m   4300\u001b[0m             state_dict,\n\u001b[1;32m   4301\u001b[0m             loaded_keys,\n\u001b[1;32m   4302\u001b[0m             start_prefix,\n\u001b[1;32m   4303\u001b[0m             expected_keys,\n\u001b[1;32m   4304\u001b[0m             device_map\u001b[38;5;241m=\u001b[39mdevice_map,\n\u001b[1;32m   4305\u001b[0m             offload_folder\u001b[38;5;241m=\u001b[39moffload_folder,\n\u001b[1;32m   4306\u001b[0m             offload_index\u001b[38;5;241m=\u001b[39moffload_index,\n\u001b[1;32m   4307\u001b[0m             state_dict_folder\u001b[38;5;241m=\u001b[39mstate_dict_folder,\n\u001b[1;32m   4308\u001b[0m             state_dict_index\u001b[38;5;241m=\u001b[39mstate_dict_index,\n\u001b[1;32m   4309\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   4310\u001b[0m             hf_quantizer\u001b[38;5;241m=\u001b[39mhf_quantizer,\n\u001b[1;32m   4311\u001b[0m             is_safetensors\u001b[38;5;241m=\u001b[39mis_safetensors,\n\u001b[1;32m   4312\u001b[0m             keep_in_fp32_modules\u001b[38;5;241m=\u001b[39mkeep_in_fp32_modules,\n\u001b[1;32m   4313\u001b[0m             unexpected_keys\u001b[38;5;241m=\u001b[39munexpected_keys,\n\u001b[1;32m   4314\u001b[0m         )\n\u001b[1;32m   4315\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   4316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda/lib/python3.11/site-packages/transformers/modeling_utils.py:895\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys)\u001b[0m\n\u001b[1;32m    884\u001b[0m     state_dict_index \u001b[38;5;241m=\u001b[39m offload_weight(param, param_name, state_dict_folder, state_dict_index)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m is_quantized\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m hf_quantizer\u001b[38;5;241m.\u001b[39mrequires_parameters_quantization)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    893\u001b[0m ):\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;66;03m# For backward compatibility with older versions of `accelerate` and for non-quantized params\u001b[39;00m\n\u001b[0;32m--> 895\u001b[0m     set_module_tensor_to_device(model, param_name, param_device, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mset_module_kwargs)\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    897\u001b[0m     hf_quantizer\u001b[38;5;241m.\u001b[39mcreate_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)\n",
      "File \u001b[0;32m/opt/anaconda/lib/python3.11/site-packages/accelerate/utils/modeling.py:400\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    398\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 400\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/anaconda/lib/python3.11/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    292\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 293\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_init()\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    297\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "politeness = politeness(data['human_turn_3'], data['llm_turn_3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235ebf3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d26921",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.insert(len(data.columns), \"metric_politeness\", politeness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08643aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "(data['human_turn_3'], data['llm_turn_3'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f91ef9a-7a90-4e3c-9ccb-884e5107495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from copy import deepcopy \n",
    "\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a50e7e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_dir = 'data/english_only/prompting_results_clean/with_metrics/' #experiment 1\n",
    "base_dir = 'data/english_only/100k_results/with_metrics/' #experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87d5d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aggregate_metrics_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e34d6881",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/shared/0/projects/research-jam-summer-2024/')\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "352ff91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wildchat_subset_en_100k_Mixtral-8x7B_end.jsonl',\n",
       " 'wildchat_subset_en_100k_Mixtral-8x7B_embeddings.npz',\n",
       " 'wildchat_subset_en_100k_Mistral-Large-Instruct_POS_DEP.jsonl',\n",
       " 'human-turn1.grammar-tool-output.csv',\n",
       " 'wildchat_subset_en_100k_Mistral-Large-Instruct.jsonl',\n",
       " 'wildchat_subset_en_100k_Llama-3.1-70B_POS_DEP.jsonl',\n",
       " 'wildchat_subset_en_100k_Mistral-Large-Instruct_end.jsonl',\n",
       " 'wildchat_subset_en_100k_Mistral-Large-Instruct_individual.jsonl',\n",
       " 'wildchat_subset_en_100k_Mistral-Large-Instruct_embeddings.npz',\n",
       " 'wildchat_subset_en_100k_Llama-3.1-70B_end.jsonl',\n",
       " 'wildchat_subset_en_100k_Mixtral-8x7B_POS_DEP.jsonl',\n",
       " 'wildchat_subset_en_100k_Mixtral-8x7B.jsonl',\n",
       " 'wildchat_subset_en_100k_Llama-3.1-70B.jsonl',\n",
       " 'wildchat_subset_en_100k_Llama-3.1-70B_embeddings.npz']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "343d7c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wildchat_subset_en_100k_Mistral-Large-Instruct.jsonl\n",
      "wildchat_subset_en_100k_Mixtral-8x7B.jsonl\n",
      "wildchat_subset_en_100k_Llama-3.1-70B.jsonl\n"
     ]
    }
   ],
   "source": [
    "for f in os.listdir(base_dir):\n",
    "    if f.startswith('wildchat_subset_en_100k') and not f.endswith('_end.jsonl') and not f.endswith('_embeddings.npz') and not f.endswith('individual.jsonl') and not f.endswith('_POS_DEP.jsonl'):\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc687bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wildchat_subset_en_100k_Mistral-Large-Instruct.jsonl\n",
      "read metrics\n",
      "read dependency parse metrics\n",
      "read embeddings\n",
      "wildchat_subset_en_100k_Mixtral-8x7B.jsonl\n",
      "read metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read dependency parse metrics\n",
      "read embeddings\n",
      "wildchat_subset_en_100k_Llama-3.1-70B.jsonl\n",
      "read metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read dependency parse metrics\n",
      "read embeddings\n"
     ]
    }
   ],
   "source": [
    "metrics = pd.concat([make_human_vs_llm_df(f, base_dir) \n",
    "                     for f in os.listdir(base_dir)\n",
    "                       if f.startswith('wildchat_subset_en_100k') and \n",
    "                       not f.endswith('_end.jsonl') and not f.endswith('_embeddings.npz') and \n",
    "                       not f.endswith('individual.jsonl') and \n",
    "                       not f.endswith('_POS_DEP.jsonl')]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1d6a52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log scale heavy-tailed count metrics\n",
    "for k in ['word_count', 'word_length', 'perplexity', \n",
    "          'dep_dpth', 'dep_brth', 'dep_dep_dist'\n",
    "         ]:\n",
    "    metrics['human_'+k] = np.log(metrics['human_'+k]+1)\n",
    "    metrics['llm_'+k] = np.log(metrics['llm_'+k]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59365f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({True: 20})\n",
      "Counter({True: 20})\n",
      "Counter({True: 4})\n",
      "Counter({True: 44})\n"
     ]
    }
   ],
   "source": [
    "# check that columns are exactly the merge keys and human/llm metrics from all_metrics \n",
    "\n",
    "print(Counter(['human_'+k in metrics.columns for k in all_metrics]))\n",
    "print(Counter(['llm_'+k in metrics.columns for k in all_metrics]))\n",
    "print(Counter([k in metrics.columns for k in merge_keys]))\n",
    "print(Counter([k in merge_keys or re.sub('human_|llm_','',k) in all_metrics \n",
    "               for k in metrics.columns]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76882430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9afd131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_category = {}\n",
    "for k in lexical: metric_category[k] = 'lexical'\n",
    "for k in syntactic: metric_category[k] = 'syntactic'\n",
    "for k in semantic: metric_category[k] = 'semantic'\n",
    "for k in style: metric_category[k] = 'style'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b7c25d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def zscore_metric(p=1):\n",
    "    print(p)\n",
    "    \n",
    "    # CREATE NORMALIZED SIMILARITIES BY Z-SCORE\n",
    "    df_zscore = metrics[merge_keys]\n",
    "    for k in all_metrics:\n",
    "        df_zscore.loc[:,'zscore_'+k] = diff_zscore(metrics['human_'+k], metrics['llm_'+k], all_metrics[k], p)\n",
    "        #sns.kdeplot(df_zscore['zscore_'+k])\n",
    "        #plt.show()\n",
    "\n",
    "    # AGGREGATED SCORES VIA Z-SCORE\n",
    "    agg = aggregate_scores(df_zscore, method = 'zscore')\n",
    "    agg['p'] = p\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dfebc6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "row_zscore = zscore_metric(p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01c1ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_zscore.to_csv('data/agg_metrics/wildchat_subset_en_100k_all_metrics_agg.csv', index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c339c21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_zscore.to_json('data/wildchat_subset_en_100k_all_normalized_metrics.jsonl', \n",
    "                   orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0429c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7cec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE COLUMN AGGREGATES WITH CORRELATION\n",
    "def corr_metric(corr_method='pearson'):\n",
    "    model = []\n",
    "    metric = []\n",
    "    cor = []\n",
    "    for mod in set(metrics.model):\n",
    "        print(mod)\n",
    "        sub = metrics[metrics.model == mod]\n",
    "        for k in all_metrics:\n",
    "            model.append(mod)\n",
    "            metric.append(k)\n",
    "            cor.append(col_diff_correlate(sub['human_'+k], sub['llm_'+k], all_metrics[k], corr_method))\n",
    "    col_corr = pd.DataFrame({'model': model, 'metric': metric, 'cor': cor, 'corr_method': corr_method})\n",
    "    col_corr['category'] = col_corr['metric'].replace(metric_category)\n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bce0755",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_corr = corr_metric('pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd3214",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_corrs = {m: corr_metric(m) for m in ['pearson','spearman','kendall']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c899f6e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6f731b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec2f3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

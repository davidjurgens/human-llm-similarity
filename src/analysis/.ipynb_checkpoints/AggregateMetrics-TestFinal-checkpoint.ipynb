{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f91ef9a-7a90-4e3c-9ccb-884e5107495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from copy import deepcopy \n",
    "\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a50e7e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data/english_only/prompting_results_clean/with_metrics/' #experiment 1\n",
    "#base_dir = 'data/english_only/100k_results/with_metrics' #experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87d5d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aggregate_metrics_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e34d6881",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/shared/0/projects/research-jam-summer-2024/')\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352ff91d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "343d7c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wildchat_subset_en_2k_prompting_Qwen2-72B-Instruct.jsonl\n",
      "wildchat_subset_en_2k_prompting_c4ai-command-r-v01.jsonl\n",
      "wildchat_subset_en_2k_prompting_Mixtral-8x7B-Instruct-v0.1.jsonl\n",
      "wildchat_subset_en_2k_prompting_Meta-Llama-3-70B-Instruct.jsonl\n",
      "wildchat_subset_en_2k_prompting_Mistral-Large-Instruct.jsonl\n",
      "wildchat_subset_en_2k_prompting_Phi-3-medium-4k-instruct.jsonl\n",
      "wildchat_subset_en_2k_prompting_Mistral-7B-Instruct-v0.3.jsonl\n",
      "wildchat_subset_en_2k_prompting_Meta-Llama-3.1-8B-Instruct.jsonl\n",
      "wildchat_subset_en_2k_prompting_Meta-Llama-3.1-70B-Instruct.jsonl\n"
     ]
    }
   ],
   "source": [
    "for f in os.listdir(base_dir):\n",
    "    if f.startswith('wildchat_subset_en_2k_prompting') and not f.endswith('_end.jsonl') and not f.endswith('_embeddings.npz') and not f.endswith('lexical.jsonl') and not f.endswith('MERGED.jsonl') and not f.endswith('_POS_DEP.jsonl'):\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc687bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wildchat_subset_en_2k_prompting_Qwen2-72B-Instruct.jsonl\n",
      "read metrics\n",
      "read dependency parse metrics\n",
      "read embeddings\n"
     ]
    }
   ],
   "source": [
    "metrics = pd.concat([make_human_vs_llm_df(f, base_dir) for f in os.listdir(base_dir)[:2]\n",
    "                       if f.startswith('wildchat_subset_en_2k_prompting') and \n",
    "                       not f.endswith('_end.jsonl') and not f.endswith('_embeddings.npz') and \n",
    "                       not f.endswith('lexical.jsonl') and not f.endswith('MERGED.jsonl') and \n",
    "                       not f.endswith('_POS_DEP.jsonl')]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc3a4e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log scale heavy-tailed count metrics\n",
    "for k in ['word_count', 'word_length', 'perplexity', 'dep_dpth', 'dep_brth', 'dep_dep_dist']:\n",
    "    metrics['human_'+k] = np.log(metrics['human_'+k]+1)\n",
    "    metrics['llm_'+k] = np.log(metrics['llm_'+k]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59365f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({True: 20})\n",
      "Counter({True: 20})\n",
      "Counter({True: 4})\n",
      "Counter({True: 44})\n"
     ]
    }
   ],
   "source": [
    "# check that columns are exactly the merge keys and human/llm metrics from all_metrics \n",
    "\n",
    "print(Counter(['human_'+k in metrics.columns for k in all_metrics]))\n",
    "print(Counter(['llm_'+k in metrics.columns for k in all_metrics]))\n",
    "print(Counter([k in metrics.columns for k in merge_keys]))\n",
    "print(Counter([k in merge_keys or re.sub('human_|llm_','',k) in all_metrics \n",
    "               for k in metrics.columns]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a6e54f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b7c25d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def zscore_metric(p):\n",
    "    # CREATE NORMALIZED SIMILARITIES BY Z-SCORE\n",
    "    df_zscore = metrics[merge_keys]\n",
    "    for k in all_metrics:\n",
    "        df_zscore.loc[:,'zscore_'+k] = diff_zscore(metrics['human_'+k], metrics['llm_'+k], all_metrics[k], p)\n",
    "        sns.kdeplot(df_zscore['zscore_'+k])\n",
    "        plt.show()\n",
    "\n",
    "    # AGGREGATED SCORES VIA Z-SCORE\n",
    "    agg = aggregate_scores(df_zscore, \n",
    "                           method = 'zscore').groupby('model')[[c for c in df_zscore \n",
    "                           if c.startswith('agg_')]].mean().transpose().reset_index()\n",
    "    agg['p'] = p\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567843de",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_zscore = [zscore_metric(p) for p in [1,2,3,0.5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820a893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a89d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d7cec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE COLUMN AGGREGATES WITH CORRELATION\n",
    "def corr_metric(corr_method):\n",
    "    model = []\n",
    "    metric = []\n",
    "    cor = []\n",
    "    for mod in set(metrics.model):\n",
    "        print(mod)\n",
    "        sub = metrics[metrics.model == mod]\n",
    "        for k in all_metrics:\n",
    "            model.append(mod)\n",
    "            metric.append(k)\n",
    "            cor.append(col_diff_correlate(sub['human_'+k], sub['llm_'+k], all_metrics[k], corr_method))\n",
    "    return pd.DataFrame({'model': model, 'metric': metric, 'cor': cor, 'corr_method': corr_method})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0fd52fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_category = {}\n",
    "for k in lexical: metric_category[k] = 'lexical'\n",
    "for k in syntactic: metric_category[k] = 'syntactic'\n",
    "for k in semantic: metric_category[k] = 'semantic'\n",
    "for k in style: metric_category[k] = 'style'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db9f8f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wildchat_subset_en_2k_prompting_Qwen2-72B-Instruct\n",
      "wildchat_subset_en_2k_prompting_Qwen2-72B-Instruct\n",
      "wildchat_subset_en_2k_prompting_Qwen2-72B-Instruct\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m col_corr \u001b[38;5;241m=\u001b[39m [corr_metric(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspearman\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkendall\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m----> 2\u001b[0m col_corr[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m col_corr[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(metric_category)\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "col_corr = [corr_metric(m) for m in ['pearson','spearman','kendall']]\n",
    "col_corr['category'] = col_corr['metric'].replace(metric_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2c947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(col_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8d36f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_corr['category'] = col_corr['metric'].replace(metric_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18bfb5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bfe941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df95080",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
